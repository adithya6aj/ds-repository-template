{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SparkSession\n",
    "spark = SparkSession.builder.appName(\"IrisTraining\").getOrCreate()\n",
    "\n",
    "# Define the path to the feature-engineered data\n",
    "feature_engineered_data_path = \"/mnt/my_delta_lake/iris_feature_engineered\" # Ensure this matches the feature engineering path\n",
    "\n",
    "# Read the feature-engineered data\n",
    "feature_engineered_df = spark.read.format(\"delta\").load(feature_engineered_data_path)\n",
    "\n",
    "# Prepare data for MLlib\n",
    "feature_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"petal_area\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(training_data, test_data) = feature_engineered_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, indexer, lr])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy = {accuracy}\")\n",
    "\n",
    "# Define the path to save the trained model\n",
    "model_path = \"/mnt/my_delta_lake/iris_model\" # Replace with your desired path\n",
    "\n",
    "# Save the trained model\n",
    "model.write().overwrite().save(model_path)\n",
    "\n",
    "print(f\"Trained model saved to: {model_path}\")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
