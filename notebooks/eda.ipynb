{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, stddev, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SparkSession\n",
    "spark = SparkSession.builder.appName(\"IrisEDA\").getOrCreate()\n",
    "\n",
    "# Define the path to the ingested data\n",
    "ingested_data_path = \"/mnt/my_delta_lake/iris_ingested\" # Ensure this matches the ingestion path\n",
    "\n",
    "# Read the Delta Lake table\n",
    "iris_df = spark.read.format(\"delta\").load(ingested_data_path)\n",
    "\n",
    "# Basic statistics\n",
    "summary_stats = iris_df.describe()\n",
    "summary_stats.show()\n",
    "\n",
    "# Group by species and calculate averages\n",
    "average_by_species = iris_df.groupBy(\"species\").agg(\n",
    "    avg(\"sepal_length\").alias(\"avg_sepal_length\"),\n",
    "    avg(\"sepal_width\").alias(\"avg_sepal_width\"),\n",
    "    avg(\"petal_length\").alias(\"avg_petal_length\"),\n",
    "    avg(\"petal_width\").alias(\"avg_petal_width\")\n",
    ")\n",
    "average_by_species.show()\n",
    "\n",
    "# You can add more EDA steps here, such as:\n",
    "# - Histograms and scatter plots (using libraries like matplotlib or seaborn)\n",
    "# - Correlation analysis\n",
    "# - Handling missing values (if any)\n",
    "# - Outlier detection\n",
    "\n",
    "# Optionally, save EDA results to Delta Lake\n",
    "eda_results_path = \"/mnt/my_delta_lake/iris_eda_results\" # Replace with your desired path\n",
    "average_by_species.write.format(\"delta\").mode(\"overwrite\").save(eda_results_path)\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
