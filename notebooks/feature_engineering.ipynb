{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0200d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SparkSession\n",
    "spark = SparkSession.builder.appName(\"IrisFeatureEngineering\").getOrCreate()\n",
    "\n",
    "# Define the path to the ingested data\n",
    "ingested_data_path = \"/mnt/my_delta_lake/iris_ingested\" # Ensure this matches the ingestion path\n",
    "\n",
    "# Read the Delta Lake table\n",
    "iris_df = spark.read.format(\"delta\").load(ingested_data_path)\n",
    "\n",
    "# Example feature engineering steps:\n",
    "# 1. Create a new feature: petal area\n",
    "iris_df = iris_df.withColumn(\"petal_area\", col(\"petal_length\") * col(\"petal_width\"))\n",
    "\n",
    "# 2. You might add more complex features based on domain knowledge or EDA insights\n",
    "#    For example, ratios of features, polynomial features, etc.\n",
    "\n",
    "# Select the features and the target variable\n",
    "feature_engineered_df = iris_df.select(\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"petal_area\", \"species\")\n",
    "\n",
    "# Define the path to save the feature-engineered data\n",
    "feature_engineered_data_path = \"/mnt/my_delta_lake/iris_feature_engineered\" # Replace with your desired path\n",
    "\n",
    "# Write the feature-engineered data to Delta Lake\n",
    "feature_engineered_df.write.format(\"delta\").mode(\"overwrite\").save(feature_engineered_data_path)\n",
    "\n",
    "print(f\"Feature-engineered data saved to: {feature_engineered_data_path}\")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
